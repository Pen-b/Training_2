{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clarans Clustering of Mixed Data-Types\n",
    "\n",
    "1. Load and transform dataset\n",
    " - fill missing values \n",
    "2. Calculate gower distance (dis-similarity between pairs of records)\n",
    "3. Apply K-Medoids partitioning\n",
    "4. Apply CLARANS partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Case Study: Auto insurance claims [dataset](https://www.kaggle.com/xiaomengsun/car-insurance-claim-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "DATA_PATH = os.path.join(os.getcwd(),'../data')\n",
    "df = pd.read_csv(os.path.join(DATA_PATH,'car_insurance_claim.csv'),low_memory=False,)\n",
    "\n",
    "# convert object to numerical\n",
    "df[['INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM', 'CLM_AMT',]] = df[['INCOME','HOME_VAL','BLUEBOOK','OLDCLAIM', 'CLM_AMT',]].replace('[^.0-9]', '', regex=True,).astype(float).fillna(0)\n",
    "\n",
    "# clean textual classes\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'O':\n",
    "        df[col] = df[col].str.upper().replace('Z_','',regex=True).replace('[^A-Z]','',regex=True)\n",
    "        \n",
    "data_types = {f:t for f,t in zip(df.columns,df.dtypes)}\n",
    "\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Encoding & Engineering\n",
    "\n",
    "***what features do we have?***\n",
    "Having explored I found this [data dictionary](https://rpubs.com/data_feelings/msda_data621_hw4) and following key definitions:\n",
    "- Bluebook = car re-sale value. \n",
    "- MVR_PTS = [MotorVehicleRecordPoints (MVR) ](https://www.wnins.com/losscontrolbulletins/MVREvaluation.pdf) details an individualâ€™s past driving history indicating violations and accidents over a specified period\n",
    "- TIF = Time In Force / customer lifetime\n",
    "- YOJ = years in job\n",
    "- CLM_FRQ = # of claims in past 5 years\n",
    "- OLDCLAIM = sum $ of claims in past 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df\n",
    "tdf = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***fill missing & mean fill***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['OCCUPATION'].fillna('OTHER',inplace=True)\n",
    "\n",
    "for col in ['AGE','YOJ','CAR_AGE']:\n",
    "    tdf[col].fillna(tdf[col].mean(),inplace=True)\n",
    "    \n",
    "print(tdf.isnull().sum()[tdf.isnull().sum()>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_id = ['ID']\n",
    "feat_account = ['KIDSDRIV', 'BIRTH', 'AGE', 'HOMEKIDS', 'YOJ', 'INCOME',\n",
    "                'PARENT1', 'HOME_VAL', 'MSTATUS', 'GENDER', 'EDUCATION', 'OCCUPATION','URBANICITY','TIF',]\n",
    "feat_car = [ 'TRAVTIME', 'CAR_USE','MVR_PTS','BLUEBOOK','CAR_TYPE', 'RED_CAR','REVOKED','CAR_AGE',]\n",
    "feat_claims = ['OLDCLAIM', 'CLM_FREQ', 'CLAIM_FLAG','CLM_AMT',]\n",
    "\n",
    "data_meta = pd.DataFrame(tdf.nunique(),columns=['num'],index=None).sort_values('num').reset_index()\n",
    "data_meta.columns = ['name','num']\n",
    "data_meta[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***transform categorical variables to label encoded***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for feat in data_meta.loc[data_meta['num']<=12,'name'].values:\n",
    "    tdf[feat] = le.fit_transform(tdf[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = tdf[feat_account+feat_car+feat_claims].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    gd = np.load(os.path.join(DATA_PATH,'car_insurance_claim_gower_distance.npy'))\n",
    "    print('Gower distances loaded from file.')\n",
    "except:\n",
    "    print('Calculating Gower dsitances...5-8 minutes')\n",
    "    %time gd = gower.gower_matrix(Xy[:])\n",
    "    np.save(os.path.join(DATA_PATH,'car_insurance_claim_gower_distance.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. CLARANS Clustering\n",
    "\n",
    "CLARANS (Clustering Large Applications based upon RANdomized Search) presents a trade-off between the cost and the effectiveness of using samples to obtain clustering.\n",
    "First, it randomly selects k objects in the data set as the current medoids. It then randomly selects a current medoid x and an object y that is not one of the current medoids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 11000\n",
    "sample = np.nan_to_num(tdf.values)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster.clarans import clarans;\n",
    "from pyclustering.utils import timedcall;\n",
    "\n",
    "\"\"\"!\n",
    "The pyclustering library clarans implementation requires\n",
    "list of lists as its input dataset.\n",
    "Thus we convert the data from numpy array to list.\n",
    "\"\"\"\n",
    "data = sample.tolist()\n",
    "\n",
    "#get a glimpse of dataset\n",
    "print(\"A peek into the dataset : \",data[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"!\n",
    "@brief Constructor of clustering algorithm CLARANS.\n",
    "@details The higher the value of maxneighbor, the closer is CLARANS to K-Medoids, and the longer is each search of a local minima.\n",
    "@param[in] data: Input data that is presented as list of points (objects), each point should be represented by list or tuple.\n",
    "@param[in] number_clusters: amount of clusters that should be allocated.\n",
    "@param[in] numlocal: the number of local minima obtained (amount of iterations for solving the problem).\n",
    "@param[in] maxneighbor: the maximum number of neighbors examined.     \n",
    "\n",
    "The higher the value of maxneighbor, the closer is CLARANS to K-Medoids, and the longer is each search of a local minima.\n",
    "\n",
    "\"\"\"\n",
    "# choose k clusters\n",
    "results = dict()\n",
    "for k in [2,10]:\n",
    "    clarans_instance = clarans(data, k, 4, 3);\n",
    "    print(k)\n",
    "    \n",
    "    #calls the clarans method 'process' to implement the algortihm\n",
    "    %time clarans_instance.process()\n",
    "\n",
    "    #returns the clusters \n",
    "    clusters = clarans_instance.get_clusters();\n",
    "\n",
    "    #returns the mediods \n",
    "    medoids = clarans_instance.get_medoids();\n",
    "    \n",
    "    result = {'clusters':cluseters,'medoids':medoids}\n",
    "    \n",
    "    results[k] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "# list of scores\n",
    "for k in results.keys():\n",
    "    cluster_array = [e for e,k in enumerate(results[k]['clusters']) for i in k]\n",
    "    score1 = silhouette_score(sample, cluster_array, metric='precomputed')\n",
    "    score2 = silhouette_score(Xy, cluster_array,metric='correlation')\n",
    "    print(f'{k} : {score1} : {score2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, n_iter=500)\n",
    "tsne = tsne_model.fit_transform(sample)\n",
    "\n",
    "tsne_df = pd.DataFrame(tsne)\n",
    "\n",
    "tsne_df['cluster'] = np.nan\n",
    "for e,k in enumerate(clusters):\n",
    "    print(e,len(k))\n",
    "    tsne_df.iloc[k,-1] = e\n",
    "    \n",
    "groups = tsne_df.groupby('cluster')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.plot(group[0], group[1], marker='o', linestyle='', label=name)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Cluster Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy['cluster'] = tsne_df['cluster'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(15,2,figsize=(6,30),sharex=True)\n",
    "\n",
    "for ax,col in zip(axs.flatten(),Xy.columns):\n",
    "    Xy.boxplot(column=col,by='cluster',ax=ax)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of scores\n",
    "cluster_array = [e for e,k in enumerate(clusters) for i in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "silhouette_score(sample, cluster_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *References*\n",
    "\n",
    "- https://towardsdatascience.com/clustering-on-mixed-type-data-8bbd0a2569c3\n",
    "- https://medium.com/@rumman1988/clustering-categorical-and-numerical-datatype-using-gower-distance-ab89b3aa90d9\n",
    "- https://www.researchgate.net/post/What_is_the_best_way_for_cluster_analysis_when_you_have_mixed_type_of_data_categorical_and_scale\n",
    "- https://www.google.com/search?client=firefox-b-d&q=python+gower+distance\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html\n",
    "- https://discuss.analyticsvidhya.com/t/clustering-technique-for-mixed-numeric-and-categorical-variables/6753\n",
    "- https://stackoverflow.com/questions/24196897/r-distance-matrix-and-clustering-for-mixed-and-large-dataset\n",
    "- https://www.analyticsvidhya.com/blog/2015/11/easy-methods-deal-categorical-variables-predictive-modeling/\n",
    "- https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02\n",
    "- https://rpubs.com/data_feelings/msda_data621_hw4\n",
    "- https://pypi.org/project/gower/\n",
    "- https://scikit-learn-extra.readthedocs.io/en/latest/generated/sklearn_extra.cluster.KMedoids.html\n",
    "- https://towardsdatascience.com/k-medoids-clustering-on-iris-data-set-1931bf781e05\n",
    "- https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/pam\n",
    "- https://github.com/annoviko/pyclustering/issues/499\n",
    "- https://stats.stackexchange.com/questions/2717/clustering-with-a-distance-matrix\n",
    "- https://www.kaggle.com/fabiendaniel/customer-segmentation\n",
    "- https://dkopczyk.quantee.co.uk/claim-prediction/\n",
    "- https://www.casact.org/pubs/dpp/dpp08/08dpp170.pdf\n",
    "- https://medium.com/analytics-vidhya/partitional-clustering-using-clarans-method-with-python-example-545dd84e58b4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine-learning]",
   "language": "python",
   "name": "conda-env-machine-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
