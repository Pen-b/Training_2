{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b9c1dde0b2464ff6778d75d84efd3ba2ef21848"
   },
   "source": [
    "## [spaCy : Faster Natural Language Processing Toolkit](https://www.kaggle.com/shivamb/spacy-text-meta-features-knowledge-graphs)\n",
    " \n",
    "- Building a Basic Knowledge Graph using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "85600930b325b2bc99c604b7535cf298e475c247"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy \n",
    "from spacy import displacy\n",
    "\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56cdec5c70d72fc837d597407ea6582e34e15781"
   },
   "source": [
    "## Basics of Knowledge Graphs using spaCy\n",
    "\n",
    "In this section, I have explained the basics of building knowledge graphs using spaCy. \n",
    "First, lets understand what are knoweldge graphs. \n",
    "\n",
    "- What are knowlege graphs ? \n",
    "> Knowledge stored in a graph form. The knowledge is captured in entities, attributes, relationships. The Nodes represents entities, NodeLabels represents attributes, and Edges represents Relationships. \n",
    "\n",
    "- Example:  \n",
    "> Chris Nolan (Director, Producer, person) ---> born in  ----> London (place) ---> Director of  ----> Interstellar (Movie) ---> shooted in  -----> Iceland (place)  \n",
    "\n",
    "- Source of information for building knowledge graphs: \n",
    "> Structured Text: Wikipedia, Dbpedia  \n",
    "> Unstructured Text: Social Media, Blogs, Images, Videos, Audios \n",
    "\n",
    "#### Main ideas for building knowlege graphs\n",
    "\n",
    "- Entity Extraction   \n",
    "In this step, the aim is to extract right entities from the text data. spaCy provides NER (Named Entity Recognition) which can be used for this purpose.  \n",
    "\n",
    "- Relationship Extraction    \n",
    "In this step, the aim is to identify the relationship between the sentences / entities. Again, by using spaCy one can extract the grammar relations between two words / entities.  \n",
    "\n",
    "- Relationship Linking    \n",
    "The hard part of knowlege graphs is to identify what kind of relationship exists between the two entities. The idea is to add the contextual sense to the relationship. \n",
    "\n",
    "Let's look at very high level implementation of this idea using spacy. Lets load a news dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "7e30860a91ef34a6d07427110f1d6ce64993bf8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>World's rarest stamp smashes sale records</td>\n",
       "      <td>http://www.thetimes.co.uk/tto/news/world/ameri...</td>\n",
       "      <td>The Times \\(subscription\\)</td>\n",
       "      <td>e</td>\n",
       "      <td>dv5GXdcteE5TwrMUj7DqIO5xDrWlM</td>\n",
       "      <td>www.thetimes.co.uk</td>\n",
       "      <td>1403086630008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300001</td>\n",
       "      <td>Murderer's Estate Sells Stamp for Record $9.5 ...</td>\n",
       "      <td>http://www.newsmax.com/US/du-Pont-Guyana-stamp...</td>\n",
       "      <td>Newsmax.com</td>\n",
       "      <td>e</td>\n",
       "      <td>dv5GXdcteE5TwrMUj7DqIO5xDrWlM</td>\n",
       "      <td>www.newsmax.com</td>\n",
       "      <td>1403087405702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300002</td>\n",
       "      <td>Stamp sells for record US$9.5m in New York</td>\n",
       "      <td>http://www.businesstimes.com.sg/breaking-news/...</td>\n",
       "      <td>THE BUSINESS TIMES \\(subscription\\)</td>\n",
       "      <td>e</td>\n",
       "      <td>dv5GXdcteE5TwrMUj7DqIO5xDrWlM</td>\n",
       "      <td>www.businesstimes.com.sg</td>\n",
       "      <td>1403087406095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                              TITLE  \\\n",
       "0  300000          World's rarest stamp smashes sale records   \n",
       "1  300001  Murderer's Estate Sells Stamp for Record $9.5 ...   \n",
       "2  300002         Stamp sells for record US$9.5m in New York   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  http://www.thetimes.co.uk/tto/news/world/ameri...   \n",
       "1  http://www.newsmax.com/US/du-Pont-Guyana-stamp...   \n",
       "2  http://www.businesstimes.com.sg/breaking-news/...   \n",
       "\n",
       "                             PUBLISHER CATEGORY  \\\n",
       "0           The Times \\(subscription\\)        e   \n",
       "1                          Newsmax.com        e   \n",
       "2  THE BUSINESS TIMES \\(subscription\\)        e   \n",
       "\n",
       "                           STORY                  HOSTNAME      TIMESTAMP  \n",
       "0  dv5GXdcteE5TwrMUj7DqIO5xDrWlM        www.thetimes.co.uk  1403086630008  \n",
       "1  dv5GXdcteE5TwrMUj7DqIO5xDrWlM           www.newsmax.com  1403087405702  \n",
       "2  dv5GXdcteE5TwrMUj7DqIO5xDrWlM  www.businesstimes.com.sg  1403087406095  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/uci-news-aggregator\"\n",
    "files = os.listdir(path)\n",
    "df = pd.read_csv(os.path.join(path,files[0]),nrows=5000)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacy_title</th>\n",
       "      <th>named_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(World, 's, rarest, stamp, smashes, sale, reco...</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Murderer, 's, Estate, Sells, Stamp, for, Reco...</td>\n",
       "      <td>((Murderer, 's), ($, 9.5, Million))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Stamp, sells, for, record, US$, 9.5, m, in, N...</td>\n",
       "      <td>((US$, 9.5, m), (New, York))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         spacy_title  \\\n",
       "0  (World, 's, rarest, stamp, smashes, sale, reco...   \n",
       "1  (Murderer, 's, Estate, Sells, Stamp, for, Reco...   \n",
       "2  (Stamp, sells, for, record, US$, 9.5, m, in, N...   \n",
       "\n",
       "                        named_entities  \n",
       "0                                   ()  \n",
       "1  ((Murderer, 's), ($, 9.5, Million))  \n",
       "2         ((US$, 9.5, m), (New, York))  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply spacy to the article titles\n",
    "df[\"spacy_title\"] = df[\"TITLE\"].apply(lambda x : nlp(x))\n",
    "\n",
    "# add field of NE\n",
    "df[\"named_entities\"] = df[\"spacy_title\"].apply(lambda x : x.ents)\n",
    "\n",
    "df[['spacy_title','named_entities']][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2099872afd539fa28784a066f2ce0c06c42a2585"
   },
   "source": [
    "## IE-Relations using POS Pattern Recognition\n",
    "#### [here is a list of POS](https://sites.google.com/site/partofspeechhelp/home/nnp_nnps#TOC-Definition-of-NNPS-Proper-Noun-Plural-Form-1)\n",
    "Now, we will define a grammar pattern / part of speech pattern to identify what type of relations we want to extract from the data. \n",
    "\n",
    "Let's we are interested in finding an action relation between two named entities. so we can define a pattern using part of speech tags as : \n",
    "\n",
    "Proper Noun - Verb - Proper Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_chain_1 = \"NNP-VBZ-NNP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98847a394b96a3abfc71e8d9ea28ed77f27d4b0a"
   },
   "source": [
    "Using spaCy, we can now iterate in text and identify what are the relevant triplets (governer, relation, dependent) or in other terms, what are the entities and relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd80efd1e651449ee42847f5859feadea27a15ee"
   },
   "outputs": [],
   "source": [
    "index_list = list()\n",
    "for i, r in df.iterrows():\n",
    "    pos_chain = \"-\".join([d.tag_ for d in r['spacy_title']])\n",
    "    if pos_chain_1 in pos_chain:\n",
    "        if len(r[\"named_entities\"]) >= 2:\n",
    "            index_list.append(i)\n",
    "            print (r[\"TITLE\"])\n",
    "            print (r[\"named_entities\"])\n",
    "            print (pos_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from these examples, one can see different entities and relations for example: \n",
    "\n",
    "- Honda --- **restructures** ---> US operations  \n",
    "- Carl Icahn --- **slams** ---> eBay CEO\n",
    "- Google --- **confirms** ---> Android SDK \n",
    "- GM --- **hires** ---> Lehman Brothers \n",
    "\n",
    "References : https://kgtutorial.github.io/\n",
    "\n",
    "\n",
    "# IE relations using NER\n",
    "\n",
    "**YOU would also want IN, eg IN-VBZ, VBZ-IN, VBZ-IN-IN, VBN-IN etc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Killer's rare stamp fetches $9 million\n",
      "NNP-POS-JJ-NN-VBZ-$-CD-CD\n",
      "(Killer, 'ORG') (fetches, 'VBZ') ($9 million, 'MONEY') \n",
      "\n",
      "Singer Katy Perry launches record label through Capitol\n",
      "NNP-NNP-NNP-VBZ-NN-NN-IN-NNP\n",
      "(Katy Perry, 'PERSON') (launches, 'VBZ') (Capitol, 'ORG') \n",
      "\n",
      "Katy Perry launches own record label, reveals first signee\n",
      "NNP-NNP-VBZ-JJ-NN-NN-,-VBZ-JJ-NN\n",
      "(Katy Perry, 'PERSON') (launches, 'VBZ') (first, 'ORDINAL') \n",
      "\n",
      "Katy Perry launches own record label, reveals first signee\n",
      "NNP-NNP-VBZ-JJ-NN-NN-,-VBZ-JJ-NN\n",
      "(Katy Perry, 'PERSON') (reveals, 'VBZ') (first, 'ORDINAL') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "limit = 4\n",
    "n = 0\n",
    "for i, r in df.iterrows():\n",
    "    if len(r[\"named_entities\"]) == 2:\n",
    "        ents = r[\"named_entities\"]\n",
    "        words = r['spacy_title']\n",
    "        pos_chain = \"-\".join([d.tag_ for d in r['spacy_title']])\n",
    "        for w in words[ents[0].end:ents[1].start]:\n",
    "            if w.tag_ == 'VBZ':\n",
    "                n += 1\n",
    "                print(words)\n",
    "                print(pos_chain)\n",
    "                print((ents[0],ents[0].label_),\n",
    "                      (w,w.tag_),\n",
    "                      (ents[1],ents[1].label_),'\\n')\n",
    "            elif w.tag_ == 'VBN':\n",
    "                n += 1\n",
    "                print(words)\n",
    "                print(pos_chain)\n",
    "                print((ents[0],ents[0].label_),\n",
    "                      (w,w.tag_),\n",
    "                      (ents[1],ents[1].label_),'\\n')\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        if n == limit:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naievely creating Triplets by extracting the verbs between Entities is not that good due to:\n",
    " - It fails on complex sentence structures. \n",
    " - It ignores other objects represented by Nouns, Propper Nouns, and Common Nouns etc. \n",
    " - Not all ENTITY types are relevant: PERSON:ORDINAL\n",
    "\n",
    "### Noun Chunks\n",
    "In addition to the above, we might consider **[Noun Chunks](https://spacy.io/usage/linguistic-features#noun-chunks)**. You can think of noun chunks as a noun plus the words describing the noun – for example, “the lavish green grass” or “the world’s largest tech fund”.\n",
    "\n",
    "    Text: The original noun chunk text.\n",
    "    Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
    "    Root dep: Dependency relation connecting the root to its head.\n",
    "    Root head text: The text of the root token’s head.\n",
    "    Children: The immediate syntactic dependents of the root token.\n",
    "    \n",
    " - spaCy uses the terms **head** and **child** to describe the words connected by a single arc in the dependency tree. \n",
    " - The term **dep** is used for the arc label, which describes the type of syntactic relation that connects the child to the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nlp(\"\"\"\\\n",
    "    Google is expanding its pool of machine learning talent with the purchase of a startup that specializes in 'instant' smartphone image recognition. \\\n",
    "    On Wednesday, French firm Moodstocks announced on its website that it's being acquired by Google, stating that it expects the deal to be completed in the next few weeks. \\\n",
    "    There's no word yet on how much Google is paying for the company. \\\n",
    "    Moodstocks' \"on-device image recognition\" software for smartphones will be phased out as it joins Google. \\\n",
    "    Moodstocks' team will also move over to Google's R&D center in Paris, according to Google's French blog. \\\n",
    "    \"Ever since we started Moodstocks, our dream has been to give eyes to machines by \\\n",
    "    turning cameras into smart sensors able to make sense of their surroundings,\" Moodstocks said in a statement on its site.\n",
    "    \"Our focus will be to build great image recognition tools within Google, \\\n",
    "    but rest assured that current paying Moodstocks customers will be able to use it until the end of their subscription.\" \n",
    "    \"\"\")\n",
    "\n",
    "words = nlp(\"Barack Obama was born in Hawaii.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "d1d96806e871e80c0fc0f9316d33db3714fdedfc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"710\" height=\"247.0\" style=\"max-width: none; height: 247.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Barack</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">Obama</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">born</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">Hawaii.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,112.0 C70,57.0 155.0,57.0 155.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,114.0 L62,102.0 78,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M180,112.0 C180,2.0 380.0,2.0 380.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,114.0 L172,102.0 188,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M290,112.0 C290,57.0 375.0,57.0 375.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,114.0 L282,102.0 298,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M400,112.0 C400,57.0 485.0,57.0 485.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M485.0,114.0 L493.0,102.0 477.0,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M510,112.0 C510,57.0 595.0,57.0 595.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595.0,114.0 L603.0,102.0 587.0,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Barack Obama\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was born in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hawaii\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk</th>\n",
       "      <th>root.text</th>\n",
       "      <th>root.dep</th>\n",
       "      <th>root.head</th>\n",
       "      <th>root.child</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Obama</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>born</td>\n",
       "      <td>[Barack]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Chunk root.text   root.dep root.head root.child\n",
       "0  Barack Obama     Obama  nsubjpass      born   [Barack]\n",
       "0        Hawaii    Hawaii       pobj        in         []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = list()\n",
    "for chunk in words.noun_chunks:\n",
    "    dat.append(pd.DataFrame([chunk.text, chunk.root.text, chunk.root.dep_,chunk.root.head.text,[c for c in chunk.root.children]]).T)\n",
    "\n",
    "print(displacy.render(words, style='dep', jupyter=True, options={'distance':110}))\n",
    "print(displacy.render(words, style='ent', jupyter=True, options={'distance':110}))\n",
    "\n",
    "dat = pd.concat(dat)\n",
    "dat.columns=['Chunk','root.text','root.dep','root.head','root.child']\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama was born in Hawaii.\n",
      "NNP-NNP-VBD-VBN-IN-NNP-.\n",
      "(Barack Obama, 'PERSON') (born, 'VBN') (Hawaii, 'GPE') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_chain = \"-\".join([d.tag_ for d in words])\n",
    "for w in words[ents[0].end:ents[1].start]:\n",
    "    ents = words.ents\n",
    "    if w.tag_ == 'VBZ':\n",
    "        n += 1\n",
    "        print(words)\n",
    "        print(pos_chain)\n",
    "        print((ents[0],ents[0].label_),\n",
    "              (w,w.tag_),\n",
    "              (ents[1],ents[1].label_),'\\n')\n",
    "    elif w.tag_ == 'VBN':\n",
    "        n += 1\n",
    "        print(words)\n",
    "        print(pos_chain)\n",
    "        print((ents[0],ents[0].label_),\n",
    "              (w,w.tag_),\n",
    "              (ents[1],ents[1].label_),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ownership\n",
    "\n",
    "Named Entity followed by : [NNS/VBZ](https://sites.google.com/site/partofspeechhelp/home/nns_vbz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Clausie](https://github.com/mmxgn/clausiepy)\n",
    "\n",
    "[these 2](https://github.com/mmxgn/miniepy/graphs/contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:training]",
   "language": "python",
   "name": "conda-env-training-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
